---
output:
  word_document: default
  #html_document: default
---


```{r setup, include=F}
knitr::opts_chunk$set(echo = TRUE)
```


### Bayesian Model for Joint SNPs analysis
The Bayesian model is designed to determine the association status of a gene, while considering known biological facts regarding the variables. Recall the determination rule that if all the SNPs on a gene have true relative risks equaled to 1, then the gene is considered as not associated with the disease. If there is least 1 SNP that has true relative risk higher than 1, then the gene is considered as associated with the disease.   
Assume on a given gene, there are total $J$ SNPs. Let $G$ be a Bernoulli variable denoting gene associated statu swith probability $b$. The probability variable $b$ ranges between 0 and 1 and follows a Beta distribution. Let $H_j$ be a Bernoulli variable denoting associated status for each $j^{th}$ SNP on the given gene. 

Recall that $R_j$ is the relative risk of the $j^{th}$ SNP on a given gene. The prior distributions of these variables are as follows:  
$$
\begin{gather}
R_j|H_j= 1 \sim Gamma(\alpha_{R_j}, \beta_{R_j}) ~where~mode~>~1 \\ 
R_j|H_j= 0 \sim Gamma(\alpha_{R0}, \beta_{R0}) ~where~mode~=~1 \\  
H_j|G=1 \sim Bernoulli(p_{j}) \\ 
H_j|G=0 \sim Bernoulli(p0) \\
b \sim Beta(\alpha_b, \beta_b)
\end{gather}
$$  
$p_{H_j}$ is significantly greater than 0 and $p0$ is small enough such that $H_j$ can be estimated by 0.

Let $\mathbf{\Theta}=\{A_1,...,A_J,M_1,...,M_J,R_1,...,R_J\}$  

$\mathbf{H}=\{H_1,...H_J\}$  
      
$\mathbf{S}= \begin{bmatrix}  
      S_{00(1)} & ... & S_{22(1)} \\
      \vdots    &     & \vdots \\
      S_{00(J)} & ... & S_{22(J)}
      \end{bmatrix}$

The joint posterior distribution is written as follows and the last equation is derived based on independence assumptions.
$$
\begin{align}
f(\mathbf{S,\Theta,H},G,b) &= f(\mathbf{S|\Theta,H},G,b) \cdot f(\mathbf{\Theta,H},G,b) \\
&= f(\mathbf{S|\Theta,H},G,b)\cdot f(\mathbf{\Theta|H},G,b)\cdot f(\mathbf{H},G,b) \\  
&= f(\mathbf{S|\Theta,H},G,b)\cdot f(\mathbf{\Theta|H},G,b)\cdot f(\mathbf{H}|G,b)\cdot f(G|b)\cdot f(b) \\ 
&= f(\mathbf{S|\Theta})\cdot f(\mathbf{\Theta|H},G)\cdot f(\mathbf{H}|G)\cdot f(G|b)\cdot f(b)
\end{align}
$$


where 

$f(\mathbf{S|\Theta}) = \prod_{j=1}^J P_{00(j)}^{S_{00(j)}}...P_{22(j)}^{S_{22(j)}}$  

$$
\begin{align}
f(\mathbf{\Theta|H},G) &= \prod_{j=1}^J f(A_j|\mathbf{H},G) f(M_j|\mathbf{H},G) f(R_j|\mathbf{H},G) \\ 
&= \prod_{j=1}^J f(A_j) f(M_j) f(R_j|\mathbf{H},G) \\ 
&= \prod_{j=1}^J f(A_j) f(M_j) f(R_j|H_j,G) \\ 
&\propto \prod_{j=1}^J [{A_j}^{\alpha_A-1} (1-A_{j})^{\beta_A-1}] \cdot [{M_j}^{\alpha_M-1} (1-M_{j})^{\beta_M-1}]\cdot [H_j {R_j}^{\alpha_{R_j}-1} e^{-R_{j} \beta_{R_j}} ~ + ~ (1-H_j) {R_j}^{\alpha_{R0}-1} e^{-R_{j} \beta_{R0}}]
\end{align}
$$  

$f(\mathbf{H}|G)= \prod_{j=1}^J f(H_j|G) = \prod_{j=1}^J [G\cdot {p_j}^{H_j} (1-p_j)^{1-H_j}+(1-G)\cdot p0^{H_j} (1-p0)^{1-H_j}]$

$f(G|b) =b^G (1-b)^{1-G}$

$f(b) \propto {b}^{\alpha_b-1} (1-b)^{\beta_b-1}$  


The posterior distribution is sampling using Metropolis-Hasting algorithm embedded in Gibbs sampler structures. The update procedure is as follows:  

#### 1. Given initial values $\mathbf{\Theta^{(0)}, H^{(0)}}, G^{(0)}, {b}^{(0)}$  
In general, assuming $\mathbf{\Theta^{(t)}, H^{(t)}}, G^{(t)}, {b}^{(t)}$, where $t=0, 1, 2,...$  

#### 2. Update $b$.  
Conditional on all other variables at state $t$.  
i) Proposal function: $b^* \sim Beta(shape= \frac {50b^{(t)}+1} {1-b^{(t)}},~ rate=52)$. The mode of the proposal function is $b^{(t)}$ and the variance is $\frac {52(50b^{(t)}+1)(1-b^{(t)})^2} {3(2b^{(t)}-53)^2(18-b^{(t)})}$. The probability of jumping between 2 states are:  
$$
\begin{align}
f(b^*|b^{(t)}) = dBeta(b^*;~ shape= \frac {50b^{(t)}+1} {1-b^{(t)}},~ rate=52) \\
f(b^{(t)}|b^*) = dBeta(b^{(t)};~ shape= \frac {50b^*+1} {1-b^*},~ rate=52)
\end{align}
$$
ii) Acceptance rate:
$$
\begin{align}
r &= \frac{lik(b^*)/f(b^*|b^{(t)})}{lik(b^{(t)})/f(b^{(t)}|b^*)} = \frac {f(G^{(t)}|b^*)f(b^*)f(b^{(t)}|b^*)} 
{f(G^{(t)}|b^{(t)})f(b^{(t)})f(b^*|b^{(t)})} \\
&= [ \frac{b^*}{b^{(t)}} ] ^ {G^{(t)}+\alpha_b-1} [ \frac{1-b^*}{1-b^{(t)}} ] ^ {\beta_b-G^{(t)}} \frac {f(b^{(t)}|b^*)} {f(b^*|b^{(t)})}
\end{align}
$$
iii) Update or maintain values.  
Define acceptance indicator: $I=rBernoulli(r,min(1))$. If acceptance indicator equals to 1, update value as $b^*$. Otherwise stay at the current value $b^{(t)}$. 
$$b^{(t+1)}={b^*} ^ {I} {b^{(t)}} ^ {1-I}$$

#### 3. Update $G$.  
i) Proposal function: Bernoulli with probability $(b^{(t+1)}+G^{(t)})/2$, conditioning on updated variable $b^{(t+1)}$ and other variables at state $t$.  If $G^{(t)}=1$, then the probability is greater than $b^{(t+1)}$, otherwise less than $b^{(t+1)}$.
$$f(G^*) \sim Bernoulli(\frac{b^{(t+1)}+G^{(t)}}{2})$$
Then there are:  
$$
\begin{align}
f(G^*|G^{(t)}) &= dBernoulli(G^*; \frac{b^{(t+1)}+G^{(t)}} {2}) \\
f(G^{(t)}|G^*) &= dBernoulli(G^{(t)}; \frac{b^{(t+1)}+G^*} {2})
\end{align}
$$
ii) Acceptance rate: 
$r=\frac{lik(G^*)/f(G^*|G^{(t)})}{lik(G^{(t)})/f(G^{(t)}|G^*)}$  
where  
$$
\begin{align}
\frac{lik(G^*)}{lik(G^{(t)})} 
  &=\frac{f(\mathbf{\Theta|H},G^*)\cdot f(\mathbf{H}|G^*)\cdot f(G^*|b)}
  {f(\mathbf{\Theta|H},G^{(t)})\cdot f(\mathbf{H}|G^{(t)})\cdot f(G^{(t)}|b)}
\\
  &=\prod_{j=1}^J 
    \frac{G^*\cdot {p_j}^{H_j} (1-p_j)^{1-H_j}+(1-G^*)\cdot p0^{H_j} (1-p0)^{1-H_j}}
    {G^{(t)}\cdot {p_j}^{H_j} (1-p_j)^{1-H_j}+(1-G^{(t)})\cdot p0^{H_j} (1-p0)^{1-H_j}} 
  ~\cdot ~\frac{b^{G^*} (1-b)^{1-G^*}}{b^{G^{(t)}} (1-b)^{1-G^{(t)}}} 
\\
  &= \prod_{j=1}^J \frac{G^*\cdot {p_j}^{H_j} (1-p_j)^{1-H_j}+(1-G^*)\cdot p0^{H_j} (1-p0)^{1-H_j}}{G^{(t)}\cdot {p_j}^{H_j} (1-p_j)^{1-H_j}+(1-G^{(t)})\cdot p0^{H_j} (1-p0)^{1-H_j}} ~\cdot ~ b^{G^*-G^{(t)}} ~\cdot ~ (1-b)^{G^{(t)}-G^*} 
\\
&=\begin{cases}
 1 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~when~~~~ G^*=G^{(t)} 
 \\
 \prod_{j=1}^J \frac{{p_j}^{H_j} (1-p_j)^{1-H_j}}{p0^{H_j} (1-p0)^{1-H_j}} \cdot \frac{b}{1-b}  ~~~~~~when~~~~ G^*=1, ~G^{(t)}=0 
 \\
 \prod_{j=1}^J \frac{p0^{H_j} (1-p0)^{1-H_j}}{{p_j}^{H_j} (1-p_j)^{1-H_j}} \cdot \frac{1-b}{b}  ~~~~~~when~~~~ G^*=0, ~G^{(t)}=1
\end{cases}
\end{align}
$$
iii) Update or maintain value.  
Define acceptance indicator: $I=rBernoulli(r,min(1))$. If acceptance indicator equals to 1, update value as $G^*$. Otherwise stay at the current value $G^{(t)}$.  
$$G^{(t+1)}={G^*} ^ {I} {G^{(t)}} ^ {1-I}$$

#### 4. Update $\mathbf{H}$.  
Assume the current step there is $\mathbf{H^{(t)}}=\{ H_1^{(t)},...H_J^{(t)}\}$ where $t=0,1,2,...$. For $j$ from 1 to $J$, update $H_j^{(t)}$ conditioned on $b^{(t+1)}, G^{(t+1)}, H_1^{(t+1)},..., H_{j-1}^{(t+1)}$ and other variables at state $t$.  

i) Proposal function: Bernoulli with probability $(p0+H_j^{(t)})/2$. So
$$
\begin{align}
f(H_j^*|H_j^{(t)})=dBernoulli(H_j^*; (p0+H_j^{(t)})/2) \\
f(H_j^{(t)}|H_j^*)=dBernoulli(H_j^{(t)}; (p0+H_j^*)/2)
\end{align}
$$
From this proposal function, it's easy to see that $H_j^{(t)}$ and $H_j^*$ are very likely to be the same.  
ii) Acceptance rate.  
$r=\frac{lik(H_j^*)/f(H_j^*|H_j^{(t)})}{lik(H_j^{(t)})/f(H_j^{(t)}|H_j^*)}$  
where  
$$\begin{align}
\frac{lik(H_j^*)}{lik(H_j^{(t)})} &\propto  \frac {f(R_j|H_j^*,G) \cdot f(H_j^*|G)}{f(R_j|H_j^{(t)},G)\cdot f(H_j^{(t)}|G)}
\\
&\propto  \frac {H_j^* {R_j}^{\alpha_{R_j}-1} exp(-R_{j} \beta_{R_j}) ~ + ~ (1-H_j^*) {R_j}^{\alpha_{R0}-1} exp(-R_{j} \beta_{R0}) } {H_j^{(t)} {R_j}^{\alpha_{R_j}-1} exp(-R_{j} \beta_{R_j}) ~ + ~ (1-H_j^{(t)}) {R_j}^{\alpha_{R0}-1} exp(-R_{j} \beta_{R0})} \cdot 
\frac {G {p_j}^{H_j^*} (1-p_j)^{1-H_j^*}+(1-G)\cdot p0^{H_j^*} (1-p0)^{1-H_j^*}}{G {p_j}^{H_j^{(t)}} (1-p_j)^{1-H_j^{(t)}}+(1-G)\cdot p0^{H_j^{(t)}} (1-p0)^{1-H_j^{(t)}}} 
\\
&=\begin{cases}
1 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~when H_j^*=H_j^{(t)} \\
{R_j}^{\alpha_{R_j}-\alpha_{R0}} exp(R_j \beta_{R0} - R_j \beta_{R_j}) \cdot \frac
{G^{(t+1)} p_j + (1-G^{(t+1)}) p0} {G^{(t+1)} (1-p_j) + (1-G^{(t+1)}) (1-p0)} ~~~~~~when H_j^*=1, H_j^{(t)}=0
\\
{R_j}^{\alpha_{R0} - \alpha_{R_j}} exp(R_j \beta_{R_j} - R_j \beta_{R0}) \cdot \frac 
{G^{(t+1)} (1-p_j) + (1-G^{(t+1)}) (1-p0)} {G^{(t+1)} p_j + (1-G^{(t+1)}) p0} ~~~~~~when H_j^*=0, H_j^{(t)}=1 
\\
\end{cases}
\end{align}
$$
here updated variables are: $G=G^{(t+1)}, \{ H_1,..., H_{j-1} \} = \{ H_1^{(t+1)},..., H_{j-1}^{(t+1)} \}$ and other variables are in state $t$.  
iii) Update or maintain values.  
Define acceptance indicator: $I=rBernoulli(r,min(1))$. If acceptance indicator equals to 1, update value as $H_j^*$. Otherwise stay at the current value $H_j^{(t)}$.  
$$H_j^{(t+1)}={H_j^*} ^ {I} {H_j^{(t)}} ^ {1-I}$$

#### 5. Update $R_j$.  
For $j$ from 1 to $J$, update $R_j^{(t)}$ conditioned on $b^{(t+1)}, G^{(t+1)}, \mathbf{H^{(t+1)}}, R_1^{(t+1)},...,R_{j-1}^{(t+1)}$ and other variables at state $t$.  

i) Proposal function:
$$f(R_j^*) \sim Gamma(shape=1+10R_j^{(t)}, rate=10)$$
By contructing shape using $R_j^{(t)}$, the mode of proposal function will be $(shape-1)/rate=R_j^{(t)}$ and variance is $shape/rate^2=0.1R_j^{(t)}+0.01$. And there are:
$$
\begin{align}
f(R_j^*|R_j^{(t)})=dGamma(R_j^*;shape=1+10R_j^{(t)}, rate=10) \\
f(R_j^{(t)}|R_j^*)=dGamma(R_j^{(t)};shape=1+10R_j^*, rate=10)
\end{align}
$$
ii) Acceptance rate:
$$
\begin{align}
r &= \frac{lik(R_j^*)/f(R_j^*|R_j^{(t)})}{lik(R_j^{(t)})/f(R_j^{(t)}|R_j^*)} \\
&\propto \frac {[P_{00(j)}^{S_{00(j)}}...P_{22(j)}^{S_{22(j)}}]|_{R_j=R_j^*} \cdot f(R_j^*|H_j)} {[P_{00(j)}^{S_{00(j)}}...P_{22(j)}^{S_{22(j)}}]|_{R_j=R_j^{(t)}} \cdot f(R_j^{(t)}|H_j)} \cdot 
\frac {f(R_j^{(t)}|R_j^*)} {f(R_j^*|R_j^{(t)})} \\
\end{align}
$$
The proportion in each cell is relatively small and may be too small to calculate when taking the power of sample sizes. Thus to calculate the ratio of proportions first, then to take power will be better.    
iii) Update or maintain values.  
Define acceptance indicator: $I=rBernoulli(r,min(1))$. If acceptance indicator equals to 1, update value as $R_j^*$. Otherwise stay at the current value $R_j^{(t)}$.  
$$R_j^{(t+1)}={R_j^*} ^ {I} {R_j^{(t)}} ^ {1-I}$$

#### 6. Update $M_j$.  
For $j$ from 1 to $J$, update $M_j^{(t)}$ conditioned on $b^{(t+1)}, G^{(t+1)}, \mathbf{H^{(t+1)}}, R_1^{(t+1)},...,R_J^{(t+1)}, M_1^{(t+1)},...,M_{j-1}^{(t+1)}$ and other variables at state $t$.  

i) Proposal function: 
$$f(R_j^*) \sim Beta(shape= \frac {1+100M_j^{(t)}}{1-M_j^{(t)}}, rate=102)$$ 
By constructing shape using $M_j^{(t)}$, the mode of proposal function (Beta) will be $(shape-1)/(shape+rate-2)=M_j^{(t)}$ and variance will be $\frac {shape \cdot rate} {(shape+rate)^2(shape+rate+1)} = \frac {102(1+100M_j^{(t)})(1-M_j^{(t)})^2} {(103-2M_j^{(t)})^2 (104-3M_j^{(t)})}$. Then there are  
$$
\begin{align}
f(M_j^*|M_j^{(t)})=dBeta(M_j^*; shape= \frac {1+100M_j^{(t)}}{1-M_j^{(t)}}, rate=102) \\
f(M_j^{(t)}|M_j^*)=dBeta(M_j^{(t)};shape= \frac {1+100M_j^*}{1-M_j^*}, rate=102)
\end{align}
$$
ii) Acceptance rate:
$$
\begin{align}
r &= \frac{lik(M_j^*)/f(M_j^*|M_j^{(t)})}{lik(M_j^{(t)})/f(M_j^{(t)}|M_j^*)} \\
&\propto \frac {[P_{00(j)}^{S_{00(j)}}...P_{22(j)}^{S_{22(j)}}]|_{M_j=M_j^*} } {[P_{00(j)}^{S_{00(j)}}...P_{22(j)}^{S_{22(j)}}]|_{M_j=M_j^{(t)}} } \cdot 
\frac {f(M_j^{(t)}|M_j^*)} {f(M_j^*|M_j^{(t)})} \\
\end{align}
$$
iii) Update or maintain values.  
Define acceptance indicator: $I=rBernoulli(r,min(1))$. If acceptance indicator equals to 1, update value as $M_j^*$. Otherwise stay at the current value $M_j^{(t)}$. 
$$M_j^{(t+1)}={M_j^*} ^ {I} {M_j^{(t)}} ^ {1-I}$$

#### 7. Update $A_j$. 
For $j$ from 1 to $J$, update $A_j^{(t)}$ conditioned on $b^{(t+1)}, G^{(t+1)}, \mathbf{H^{(t+1)}}, R_1^{(t+1)},...,R_J^{(t+1)}, M_1^{(t+1)},...,M_J^{(t+1)},A_1^{(t+1)},...,A_{j-1}^{(t+1)}$ and other variables at state $t$.  

i) Proposal function:
$$f(A_j^*) \sim Beta(shape= \frac {1+100A_j^{(t)}}{1-A_j^{(t)}}, rate=102)$$
    By constructing shape using $A_j^{(t)}$, the mode of proposal function (Beta) will be $(shape-1)/(shape+rate-2)=A_j^{(t)}$ and variance will be $\frac {shape \cdot rate} {(shape+rate)^2(shape+rate+1)} = \frac {102(1+100A_j^{(t)})(1-A_j^{(t)})^2} {(103-2A_j^{(t)})^2 (104-3A_j^{(t)})}$. Then there are  
$$
\begin{align}
f(A_j^*|A_j^{(t)})=dBeta(A_j^*; shape= \frac {1+100A_j^{(t)}}{1-A_j^{(t)}}, rate=102) \\
f(A_j^{(t)}|A_j^*)=dBeta(A_j^{(t)};shape= \frac {1+100A_j^*}{1-A_j^*}, rate=102)
\end{align}
$$
ii) Acceptance rate:  
$$
\begin{align}
r &= \frac{lik(A_j^*)/f(A_j^*|A_j^{(t)})}{lik(A_j^{(t)})/f(A_j^{(t)}|A_j^*)} \\
&\propto \frac {[P_{00(j)}^{S_{00(j)}}...P_{22(j)}^{S_{22(j)}}]|_{A_j=A_j^*} } {[P_{00(j)}^{S_{00(j)}}...P_{22(j)}^{S_{22(j)}}]|_{A_j=A_j^{(t)}} } \cdot 
\frac {f(A_j^{(t)}|A_j^*)} {f(A_j^*|A_j^{(t)})} \\
\end{align}
$$
iii) Update or maintain values.  
Define acceptance indicator: $I=rBernoulli(r,min(1))$. If acceptance indicator equals to 1, update value as $A_j^*$. Otherwise stay at the current value $A_j^{(t)}$. 
$$A_j^{(t+1)}={A_j^*} ^ {I} {A_j^{(t)}} ^ {1-I}$$


